---
layout: project
title: "ML Trading Strategist: Advanced Algorithmic Trading Framework"
categories: machine-learning finance reinforcement-learning data-science
image: /assets/images/ml-trading-strategist.jpg
technologies: [Python, Pandas, Scikit-learn, Streamlit, NumPy, YAML, Reinforcement Learning, Technical Analysis, Backtesting]
github: https://github.com/Adredes-weslee/ML-Trading-Strategist
blog_post: /ai/finance/machine-learning/reinforcement-learning/2025/05/12/ml-trading-strategist-comparing-learning-approaches.html
streamlit_app: https://adredes-weslee-ml-trading-strategist-app-pu7qym.streamlit.app/
---

## Project Overview

Developed a modular machine learning framework for algorithmic trading strategy development, testing, and comparison. This comprehensive platform enables traders and researchers to experiment with different approaches to market prediction. Key capabilities include:

* **Multiple Strategy Models**: Implementation of manual rule-based strategies, decision tree ensembles (Tree Strategy Learner), and reinforcement learning (Q-Strategy Learner with Dyna-Q).
* **Realistic Backtesting**: A market simulator that accounts for trading costs like commissions and market impact (slippage).
* **Comprehensive Technical Indicator Library**: Tools for feature engineering using common financial indicators.
* **Performance Analysis**: Robust metrics and visualizations for strategy evaluation.
* **Configuration System**: YAML-based setup for reproducible experiments.
* **Interactive UI**: A Streamlit web application for strategy configuration, execution, and visualization of results.

<div class="demo-link-container">
  <a href="https://adredes-weslee-ml-trading-strategist-app-pu7qym.streamlit.app/" class="demo-button" target="_blank" rel="noopener noreferrer">
    <i class="fas fa-play-circle"></i> Try the Live Demo
  </a>
</div>

## Business Problem & Context

Traditional algorithmic trading and the application of machine learning in finance face several challenges that this project aims to address:

1.  **Strategy Comparison Complexity**: Evaluating diverse trading approaches (rule-based vs. ML) on a consistent basis is difficult.
2.  **Unrealistic Backtesting**: Many frameworks overlook crucial real-world factors like commissions, slippage, and market impact, leading to overly optimistic results.
3.  **Feature Engineering Burden**: Selecting and tuning relevant technical indicators often requires significant domain expertise and iterative effort.
4.  **Overfitting Risk**: ML models can easily overfit to historical market data, performing poorly on unseen data.
5.  **Production-Research Gap**: Transitioning strategies from research environments to live production systems often requires substantial re-engineering.

This framework provides tools to mitigate these issues by enabling systematic experimentation and robust evaluation.

## System Architecture

The platform is designed with a modular architecture, separating concerns for clarity and extensibility.

### System Components

* **Data Management Layer**: Handles loading, cleaning, and preprocessing of historical price data from various sources (e.g., CSV files, APIs).
* **Technical Indicator Library**: Provides functions to calculate a wide range of financial technical indicators (RSI, Bollinger Bands, MACD, Momentum, CCI, etc.).
* **Strategy Models**:
    * **Manual Strategy**: A baseline rule-based approach using technical indicator thresholds and a voting mechanism.
    * **Tree Strategy Learner**: A supervised learning model using a bagged ensemble of random decision trees to predict future returns and generate trading signals.
    * **Q-Strategy Learner**: A reinforcement learning agent that learns optimal trading policies using Q-learning, with an optional Dyna-Q component for model-based planning.
* **Market Simulator**: Executes trades generated by strategies and calculates portfolio values, incorporating configurable commission costs and market impact.
* **Performance Analysis Module**: Computes key performance metrics (e.g., cumulative return, Sharpe ratio, max drawdown) and generates visualizations.
* **Configuration System**: Utilizes YAML files for managing all parameters related to data, strategy, simulation, and evaluation, ensuring experiment reproducibility.
* **Streamlit User Interface**: An interactive web application allowing users to configure experiments, run simulations, and visualize results and comparisons.

### System Architecture Diagram

```mermaid
graph TD
    A[User Interface - Streamlit] --> B[Strategy Configuration (YAML)]
    A --> C[Data Loading & Management]
    C --> D[Data Preprocessing]
    D --> I[Technical Indicator Library]

    B --> E[Strategy Selection]
    E --> F[Manual Strategy]
    E --> G[Tree Strategy Learner]
    E --> H[Q-Strategy Learner]
    
    F -- Uses --> I
    G -- Uses --> I
    H -- Uses --> I
    
    F --> J[Trade Signal Generation]
    G --> J
    H --> J
    
    J --> K[Market Simulator]
    K --> L[Performance Metrics Calculation]
    L --> M[Results Visualization]
    M --> A
```

## Core Features & Technical Components

### 1. Strategy Models Implemented

#### a. Manual Strategy
A baseline, rule-based strategy. It generates buy/sell signals based on predefined thresholds for multiple technical indicators (RSI, Bollinger Bands, MACD). A voting system combines these individual signals to make a final trading decision.

#### b. Tree Strategy Learner
This supervised learning model employs an ensemble of bagged random decision trees.
* **Feature Engineering**: Uses technical indicators as input features.
* **Label Generation**: Creates target labels (buy/sell/hold) based on whether future returns (e.g., 5 days ahead) exceed specified buy/sell thresholds.
* **Ensemble Method**: Utilizes bootstrap aggregation (bagging) and random feature selection within trees to improve generalization and reduce overfitting.

```python
class TreeStrategyLearner:
    def __init__(self, leaf_size=5, bags=20, boost=False, 
                 buy_threshold=0.02, sell_threshold=-0.02, prediction_days=5, verbose=False):
        self.leaf_size = leaf_size
        self.bags = bags
        # ... other initializations ...
        self.model = None # Will hold the ensemble of tree learners

    def addEvidence(self, symbol, sd, ed, sv):
        # 1. Load price data for the symbol within start date (sd) and end date (ed)
        # 2. Compute technical indicators (features) from price data
        # 3. Generate labels based on future returns and thresholds
        # 4. Create 'bags' number of decision tree learners (e.g., RTLearner)
        # 5. For each bag:
        #    a. Create a bootstrap sample of the features and labels
        #    b. Train a decision tree learner on this sample
        #    c. Store the trained learner
        # self.model now holds the ensemble of trained trees
        pass
        
    def testPolicy(self, symbol, sd, ed, sv):
        # 1. Load price data for the symbol for the test period
        # 2. Compute technical indicators (features)
        # 3. For each day in the test period:
        #    a. Get predictions from all trees in the ensemble (self.model)
        #    b. Aggregate predictions (e.g., majority vote or average)
        #    c. Convert aggregated prediction to a trading action (buy, sell, hold shares)
        # 4. Return a DataFrame of trades (date, symbol, order type, shares)
        pass
```

#### c. Q-Strategy Learner
This model applies reinforcement learning (Q-learning) to find an optimal trading policy.
* **State Representation**: Discretizes the market state based on binned values of technical indicators.
* **Q-Learning Algorithm**: Iteratively updates state-action values (Q-values) in a Q-table based on rewards received from the market environment.
* **Exploration vs. Exploitation**: Employs an epsilon-greedy policy with a decaying random action rate (rar) to balance exploring new actions and exploiting known good actions.
* **Dyna-Q**: Optionally incorporates Dyna-Q, a model-based RL technique, to perform "planning" updates using a learned model of the environment, improving sample efficiency.

```python
class QStrategyLearner:
    def __init__(self, indicator_bins=10, num_actions=3, learning_rate=0.2, 
                 discount_factor=0.9, random_action_rate=0.5,
                 random_action_decay=0.99, dyna_iterations=10, verbose=False):
        self.indicator_bins = indicator_bins # Bins per indicator for state discretization
        self.num_actions = num_actions # Typically buy, sell, hold
        self.alpha = learning_rate
        self.gamma = discount_factor
        # ... other initializations for Q-table, Dyna-Q model (T, R) ...
        
    def _discretize_state(self, indicators_values):
        # Convert continuous indicator values to a single discrete state index
        pass

    def addEvidence(self, symbol, sd, ed, sv):
        # 1. Load price data and compute indicators
        # 2. Iterate through training data day by day:
        #    a. Determine current discretized state (s)
        #    b. Choose an action (a) using epsilon-greedy policy based on Q[s,:]
        #    c. Execute action, observe reward (r) and next state (s_prime)
        #    d. Update Q[s, a] using the Q-learning update rule:
        #       Q[s,a] = (1-alpha)*Q[s,a] + alpha*(r + gamma*max(Q[s_prime,:]))
        #    e. If Dyna-Q is enabled:
        #       i. Update transition model T(s,a) -> s_prime and reward model R(s,a) -> r
        #       ii. Perform 'dyna_iterations' of planning: randomly sample previous (s,a), predict s_prime, r from model, and update Q[s,a]
        #    f. Decay random_action_rate
        pass
        
    def testPolicy(self, symbol, sd, ed, sv):
        # 1. Load price data and compute indicators for the test period
        # 2. For each day:
        #    a. Determine current discretized state (s)
        #    b. Choose the action (a) that maximizes Q[s,:] (greedy policy)
        #    c. Convert action to trades
        # 3. Return DataFrame of trades
        pass
```

### 2. Realistic Market Simulator
Crucial for reliable strategy evaluation, the simulator models real-world trading conditions.
```python
def compute_portvals(orders_df, start_val=100000.0, commission=9.95, impact=0.005, prices_df=None):
    """
    Simulate trading with realistic costs and compute portfolio values.
    
    Parameters:
    -----------    
    orders_df : pd.DataFrame
        Trading orders (dates as index, symbols as columns, values are shares traded).
    start_val : float
        Initial portfolio cash value.
    commission : float
        Fixed commission cost per trade.
    impact : float
        Market impact (slippage) as a percentage of trade value.
    prices_df: pd.DataFrame
        DataFrame of daily prices for the traded symbols.
        
    Returns:
    --------
    pd.Series
        Daily portfolio values over time.
    """
    # Implementation details:
    # 1. Initialize portfolio: cash = start_val, holdings = 0 for all symbols.
    # 2. Iterate through dates in orders_df:
    #    For each symbol with an order on that date:
    #    a. Get current price from prices_df.
    #    b. Calculate trade value.
    #    c. Adjust cash: subtract (trade_value + commission + abs(trade_value * impact)).
    #    d. Update holdings for the symbol.
    # 3. Calculate daily total portfolio value (cash + market value of all holdings).
    pass
```

### 3. Technical Indicator Library
A comprehensive set of functions to calculate various technical indicators used for feature engineering. Example:
```python
def bollinger_indicator(prices_df, symbol, window=20, num_std=2):
    """Calculate Bollinger Bands indicator values, normalized."""
    prices = prices_df[symbol]
    rolling_mean = prices.rolling(window=window).mean()
    rolling_std = prices.rolling(window=window).std()
    
    upper_band = rolling_mean + (rolling_std * num_std)
    lower_band = rolling_mean - (rolling_std * num_std)
    
    # Normalized Bollinger value: (price - SMA) / (num_std * StdDev)
    # This value is typically between -1 and 1 if price is within bands.
    bb_value = (prices - rolling_mean) / (rolling_std * num_std)
    return pd.DataFrame(bb_value, index=prices.index, columns=['bollinger'])
```

### 4. Configuration Management
Experiments are defined using YAML files, ensuring all parameters (data sources, date ranges, strategy hyperparameters, simulation costs) are explicitly stated and versionable.
```yaml
# Example: tree_strategy_config.yaml
data:
  symbol: JPM
  training_period:
    start_date: '2008-01-01'
    end_date: '2009-12-31'
  testing_period:
    start_date: '2010-01-01'
    end_date: '2011-12-31'

strategy:
  type: TreeStrategyLearner
  parameters:
    leaf_size: 5
    bags: 20
    buy_threshold: 0.02
    sell_threshold: -0.02
    prediction_days: 5

simulation:
  commission: 9.95
  impact: 0.005
  starting_value: 100000
```

## Performance Evaluation & Results

Strategies are evaluated using a standard set of financial metrics:

| Metric                        | Description                                         |
| ----------------------------- | --------------------------------------------------- |
| Cumulative Return             | Total percentage return over the period.            |
| Average Daily Return          | Mean of daily percentage returns.                   |
| Std. Dev. of Daily Returns    | Volatility; standard deviation of daily returns.    |
| Sharpe Ratio                  | Risk-adjusted return (vs. risk-free rate).          |
| Maximum Drawdown              | Largest peak-to-trough percentage decline.          |
| Number of Trades              | Total trading activity.                             |

### Comparative Results (JPM Stock, Test Period: 2010-2011)
![Strategy Performance Comparison](/assets/images/Strategy Performance Comparison.jpg)

| Strategy        | Cumulative Return | Sharpe Ratio (Annualized) | Max Drawdown | # Trades |
| --------------- | ----------------- | ------------------------- | ------------ | -------- |
| Benchmark       | +23.5%            | 0.72                      | -19.2%       | 1        |
| Manual Strategy | +31.2%            | 1.05                      | -15.3%       | 15       |
| Tree Strategy   | +42.7%            | 1.48                      | -12.1%       | 23       |
| Q-Strategy      | +37.9%            | 1.31                      | -13.8%       | 19       |

### Key Findings
1.  **ML Strategies Outperform**: Both the Tree Strategy and Q-Strategy demonstrated superior cumulative returns and risk-adjusted returns (Sharpe Ratio) compared to the manual strategy and the buy-and-hold benchmark.
2.  **Feature Importance**: For the Tree Strategy on JPM data, Bollinger Bands and RSI were identified as the most predictive technical indicators.
3.  **Hyperparameter Sensitivity**: Performance of ML strategies was sensitive to key hyperparameters (e.g., `prediction_days` and `leaf_size` for Tree Strategy; `learning_rate` and `indicator_bins` for Q-Strategy).
4.  **Market Regime Dependency**: Strategy performance can vary significantly across different market conditions (e.g., trending vs. sideways markets, high vs. low volatility). Continuous monitoring and potential retraining are implied.

## Deployment & Usage
The project is containerized for ease of deployment and includes a Streamlit application for interactive use.
```bash
# 1. Clone the repository
git clone [https://github.com/Adredes-weslee/ML-Trading-Strategist.git](https://github.com/Adredes-weslee/ML-Trading-Strategist.git)
cd ML-Trading-Strategist

# 2. Create and activate Conda environment (recommended)
conda env create -f environment.yaml
conda activate trading-strategist

# 3. Run the Streamlit application
streamlit run app.py
```
Users can then configure strategies, run backtests, and view results through the web interface.

## Skills & Tools
* **Programming**: Python
* **Libraries**: Pandas, NumPy, Scikit-learn
* **Machine Learning**: Decision Trees, Ensemble Methods (Bagging), Reinforcement Learning (Q-learning, Dyna-Q)
* **Financial Analysis**: Technical Indicators, Backtesting, Portfolio Metrics
* **Software Engineering**: Modular Design, Configuration Management (YAML)
* **Visualization/UI**: Streamlit

## Conclusion

The ML Trading Strategist framework provides a robust and flexible platform for the development, comparison, and evaluation of algorithmic trading strategies. By incorporating realistic backtesting and offering a range of modeling approaches from simple rule-based systems to sophisticated machine learning techniques like ensemble trees and reinforcement learning, it empowers users to gain deeper insights into strategy performance and market dynamics. The results indicate that ML-driven strategies, when carefully designed and validated, can offer a significant edge in financial markets.

## Future Enhancements
* Integration of more advanced deep learning models (e.g., LSTMs, Transformers for sequence modeling).
* Expansion of the technical indicator library and feature engineering capabilities.
* Incorporation of alternative data sources (e.g., news sentiment, economic indicators).
* Development of more sophisticated portfolio optimization and risk management modules.
* Tools for automated hyperparameter optimization.

---

*For an in-depth discussion on the development and comparative analysis of the various trading strategies within this framework—from rule-based systems to decision tree ensembles and reinforcement learning—including implementation details and specific insights, please see our [accompanying blog post: "Developing ML Trading Strategies: From Rule-Based Systems to Reinforcement Learning"](/ai/finance/machine-learning/reinforcement-learning/2025/05/12/ml-trading-strategist-comparing-learning-approaches.html). The complete source code and documentation for the framework are available on [GitHub](https://github.com/Adredes-weslee/ML-Trading-Strategist).*

